# Must create a serial port in Proxmox to appease systemd-vconsole-setup.service
---
- name: "CoreOS configuration playbook"
  hosts: "coreos"
  gather_facts: false
  become: true

  handlers:
    - name: "Reboot Server"
      ansible.builtin.reboot:

    - name: "Reload Docker service"
      ansible.builtin.systemd_service:
        name: "docker.service"
        state: "restarted"

  pre_tasks:
    - name: "Preload Ansible SSH Key"
      tags: "always"
      ansible.builtin.import_tasks: "../tasks/load_ssh_key.yml"

  tasks:
    # Gather facts now that we've loaded the SSH key
    - name: "Gathering Facts"
      tags: "always"
      ansible.builtin.setup:

    - name: "Zincati - Set update wariness"
      ansible.builtin.copy:
        content: |
          [identity]
          rollout_wariness = 0.5
        dest: "/etc/zincati/config.d/51-rollout-wariness.toml"
        mode: "0644"

    - name: "Zincati - Set update strategy"
      ansible.builtin.copy:
        content: |
          [updates]
          strategy = "periodic"
          [[updates.periodic.window]]
          days = [ "Sat" ]
          start_time = "09:00"
          length_minutes = 60
        dest: "/etc/zincati/config.d/55-updates-strategy.toml"
        mode: "0644"

    - name: "QEMU-GA - Create unit for qemu-guest-agent"
      ansible.builtin.copy:
        content: |
          [Unit]
          Description=QEMU Guest Agent
          After=network-online.target
          Wants=network-online.target
          ConditionVirtualization=kvm

          [Service]
          ExecStartPre=docker rm -fv qemu-ga
          ExecStart=docker run --name qemu-ga --privileged --net=host -v /dev:/dev -v /etc/os-release:/etc/os-release:ro docker.io/danskadra/qemu-ga qemu-ga

          [Install]
          WantedBy=multi-user.target
        dest: "/etc/systemd/system/qemu-ga.service"
        mode: "0644"

    - name: "QEMU-GA - Start QEMU Guest Agent"
      ansible.builtin.systemd_service:
        name: "qemu-ga.service"
        state: "started"
        enabled: true

    - name: "Install rpm-ostree packages"
      community.general.rpm_ostree_pkg:
        name:
          - "autofs"
          - "bmon"
          - "htop"
          - "iftop"
          # RPM Fusion repos
          - "https://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-{{ ansible_distribution_major_version }}.noarch.rpm"
          - "https://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-{{ ansible_distribution_major_version }}.noarch.rpm"
      notify: "Reboot Server"

    - name: "Run handlers"
      ansible.builtin.meta: flush_handlers

    - name: "Nvidia-specific installation"
      tags: ["never", "nvidia"]
      block:
        - name: "Add the nvidia-container-toolkit repo"
          ansible.builtin.get_url:
            dest: "/etc/yum.repos.d/nvidia-container-toolkit.repo"
            mode: "0644"
            url: "https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo"

        - name: "Install GPU-related rpm-ostree packages"
          community.general.rpm_ostree_pkg:
            name:
              # Nvidia drivers
              - "akmod-nvidia"
              - "xorg-x11-drv-nvidia-cuda"
              - "nvidia-container-toolkit"
              # Utils useful for Nvidia GPU stuff
              - "python3-pip"
              - "pciutils" # lspci
              - "lshw"
              - "nvtop"
          notify: "Reboot Server"

        - name: "Run handlers"
          ansible.builtin.meta: flush_handlers

        - name: "Install pip packages"
          ansible.builtin.pip:
            name: gpustat

        - name: "Disable the nvidia-powerd service"
          ansible.builtin.systemd_service:
            enabled: false
            name: "nvidia-powerd.service"
          notify: "Reboot Server"

        - name: "Run handlers"
          ansible.builtin.meta: flush_handlers

        - name: "Get stats on /etc/cdi/nvidia.yaml"
          ansible.builtin.stat:
            path: "/etc/cdi/nvidia.yaml"
          register: nvidia_cdi_config

        - name: "Generate Nvidia CDI config"
          ansible.builtin.command: "nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml"
          changed_when: false
          when: nvidia_cdi_config.stat.exists is defined and not nvidia_cdi_config.stat.exists

        - name: "Verify the Nvidia CDI config"
          ansible.builtin.command: "nvidia-ctk cdi list"
          changed_when: false
          failed_when: "'nvidia.com/gpu=0' not in nvidia_cdi_verify.stdout"
          register: nvidia_cdi_verify

        - name: "Check Nvidia config in /etc/docker/daemon.json"
          ansible.builtin.command: grep -q nvidia-container-runtime /etc/docker/daemon.json
          register: nvidia_docker_config
          changed_when: nvidia_docker_config.rc in [1, 2]
          failed_when: nvidia_docker_config.rc not in [0, 1, 2]

        - name: "Generate Nvidia Docker config"
          ansible.builtin.command: "nvidia-ctk runtime configure --runtime=docker"
          notify: "Reload Docker service"
          register: nvidia_docker_config_generated
          when: nvidia_docker_config.changed

        - name: "Run handlers"
          ansible.builtin.meta: flush_handlers

        - name: "Create systemd task to generate CTK config at boot"
          ansible.builtin.copy:
            content: |
              [Unit]
              Description=Nvidia CDI Config Generator

              [Service]
              Type=oneshot
              ExecStart=nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml

              [Install]
              WantedBy=multi-user.target docker.socket
            dest: "/etc/systemd/system/nvidia-cdi-gen.service"
            mode: "0644"

        - name: "Enable Nvidia CDI generation task"
          ansible.builtin.systemd_service:
            name: "nvidia-cdi-gen.service"
            enabled: true

    - name: "AutoFS - Copy master template"
      ansible.builtin.template:
        dest: "/etc/auto.master"
        force: true
        mode: "0644"
        src: "{{ inventory_dir }}/templates/auto.master.j2"
      register: autofs_master

    - name: "AutoFS - Copy direct map template"
      ansible.builtin.template:
        dest: "/etc/auto-direct.maps"
        force: true
        mode: "0644"
        src: "{{ inventory_dir }}/templates/auto-direct.maps.j2"
      register: autofs_direct

    - name: "AutoFS - Copy indirect maps template"
      ansible.builtin.template:
        dest: "/etc/auto-{{ item.clientPath | basename }}.maps"
        force: true
        mode: "0644"
        src: "{{ inventory_dir }}/templates/auto-indirect.maps.j2"
      loop: "{{ nfs_indirect_map }}"
      loop_control: { label: "{{ item.clientPath | basename }}" }
      register: autofs_indirect

    - name: "AutoFS - Enable and start the service"
      ansible.builtin.systemd_service:
        enabled: true
        name: "autofs.service"
        state: "{{ 'reloaded' if autofs_master.changed or autofs_direct.changed or autofs_indirect.changed else 'started' }}"

    - name: "Import the users playbook"
      ansible.builtin.import_tasks: "../tasks/configure_users.yml"

    - name: "Import the Docker playbook"
      ansible.builtin.import_tasks: "../tasks/configure_docker.yml"

    - name: "Import the networking playbook"
      ansible.builtin.import_tasks: "../tasks/configure_networking.yml"

    - name: "Import the SSH playbook"
      ansible.builtin.import_tasks: "../tasks/configure_ssh.yml"

    - name: "Unmonitored reboot"
      ansible.builtin.shell: "sleep 5 && reboot"
      async: 1
      changed_when: false
      poll: 0
      args:
        executable: "/bin/bash"
      when: update_eth_name.changed or
            created_server_vlan.changed or
            created_storage_vlan.changed or
            disable_primary_interface.changed

  post_tasks:
    - name: "Unload Ansible SSH Key"
      tags: always
      ansible.builtin.import_tasks: "../tasks/unload_ssh_key.yml"
...
